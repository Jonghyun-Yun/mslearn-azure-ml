{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Work with Compute\n",
        "\n",
        "When you run a script as an Azure Machine Learning job, you need to define the execution context for the job run. One key configuration is the compute target on which the script will be run. This could be the local workstation (in this case the compute instance), or a remote compute target such as the Azure Machine Learning managed compute cluster that is provisioned on-demand.\n",
        "\n",
        "In this notebook, you'll create a compute cluster and explore compute targets for jobs.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.13.0\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/mslearn/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1665745893251
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1708721273929
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "ml_client = MLClient(DefaultAzureCredential(), ws.subscription_id, ws.resource_group ,ws.name)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708721379607
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a compute cluster\n",
        "\n",
        "In many cases, your local compute resources may not be sufficient to process a complex or long-running experiment that needs to process a large volume of data; and you may want to take advantage of the ability to dynamically create and use compute resources in the cloud. Azure Machine Learning supports a range of compute targets, which you can define in your workpace and use to run jobs; paying for the resources only when using them.\n",
        "\n",
        "You can create a compute cluster in [Azure Machine Learning studio](https://ml.azure.com), by using the Python SDK, or the Azure CLI. The following code cell checks your workspace for the existence of a compute cluster names `aml-cluster`, and if it doesn't exist, creates it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"aml-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS11_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=2,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=120,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1665746211525
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "After you've created a compute cluster, you can only change the configuration for:\n",
        "\n",
        "- `min_instances`: Minimum number of nodes\n",
        "- `max_instances`: Maximum number of nodes\n",
        "- `idle_time_before_scale_down`: Idle time before scale down\n",
        "\n",
        "Currently, your compute cluster `aml-cluster` can only scale do a maximum of one node. Let's change that to two, to allow for parallel compute."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cluster_scale = AmlCompute(\n",
        "    name=\"aml-cluster\",\n",
        "    max_instances=2,\n",
        ")\n",
        "ml_client.begin_create_or_update(cluster_scale)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1665746829045
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "When the compute cluster is updated, you can verify its configuration by printing its attributes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_cluster = ml_client.compute.get(\"baplowprgr020cc99\")\n",
        "\n",
        "print (\n",
        "        f\"AMLCompute with name {cpu_cluster.name} has a maximum of {cpu_cluster.max_instances} nodes\"\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AMLCompute with name baplowprgr020cc99 has a maximum of 6 nodes\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1708721498762
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a script to train a model\n",
        "\n",
        "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/diabetes-training.py\n",
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# set regularization hyperparameter\n",
        "reg = 0.01\n",
        "\n",
        "# train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing src/diabetes-training.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Run a job on a compute cluster\n",
        "\n",
        "Now, you're ready to run the job on the compute cluster you created.\n",
        "\n",
        "> **Note**:\n",
        "> The job will take some time to start as the compute cluster will need to scale from zero to one node. Once the compute cluster is ready, the script will be run. When the job has finished, the compute cluster will scale back down to zero nodes. You can review the compute cluster's status in the **Compute** page."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python diabetes-training.py\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"baplowprgr020cc99\",\n",
        "    display_name=\"diabetes-train-cluster\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.52 MBs): 100%|██████████| 519221/519221 [00:00<00:00, 5631825.80it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/plucky_kettle_2ssymqhs7s?wsid=/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourcegroups/ba-p-zeaus-group020-rg/workspaces/p-group020-aml-ws-001&tid=49793faf-eb3f-4d99-a0cf-aef7cce79dc1\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1708721699601
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs = ml_client.environments.list()\n",
        "for env in envs:\n",
        "    print(env.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OR_TechOps_Check_Schedule_Optimizer_CSO\nATANew\njordan-spark-env\nATARec_Test4\nATARec_Test3\nATARec_Test2\nATARec_Test\nATARec_Part1\nata_recoder_2\npeanuts-env\nFP_info_env\ncontact_core\nCall_intent_ben\nCatboost_Raven_Cost_env\ncr-wb\nbt_dl_nlp_env\nben_dl_nlp_ml_env\nBen_dl_nlp_env\nCR-write-backs\nDefaultNcdEnv-foundation-model-inference\npyspark_direct\nor\nPyspark\nCall_intent\ncbiml_env\nata_recoder_mainline\nray-on-aml-791941756\nray-on-aml-791286394\npsa_ata_recoder\nBERTopic_NLP_Sentiment\nray-0.0.7-882696435559256090\nray-0.0.7-1929789251511173533\nray-0.0.7-4368720963963524077\nray-0.0.7-490915851933497220\nray-0.0.7-4984194963193669933\nray-0.0.7-111651646124021611\nray-on-aml-398791205\nOR_TechOps_Wally_Task_Specific_Test\nata_recoder\njava-test-2\ndefault-environment\nor_general\n3837fc50-b7d1-435f-a0af-cd07d5356956\ntest-java\nopen-JDK\nac_tutorial_gpu_env\ncust-img-demo\ndr-pipeline-dbc-env\ntest-jdbc-env\ncustom-image-test\ndr-manual-env-test\nGRB_TEST\nXPRS_TEST\nOR_TechOps_ATARec\nGurobi_test\nac_tutorial_env\ncust-core\ndr-manual-env\ndr-poc-drift-env\nExperiment dr-model-monitor-Monitor-Runs Environment\nExperiment test-detector-two-jnl-Monitor-Runs Environment\nOR_TechOps_Wally_Task_Specific_2202F0_v2\nOR_TechOps_Wally_Task_Specific_2202F0\nExperiment DataDrift_Schedule_Run Environment\nOR_TechOps_Wally_Task_Specific\nExperiment test-drift-detector-jnl-Monitor-Runs Environment\ndr-pipeline-env\nclient-env\ntest-cust-img\narts_env\nfastai2\ndr-data-prep-train-env-sample\ntest-dbc-env\ndr-data-prep-env-sample\ndr-poc-env\ntfcustom2\nkeras-env\nmlops-dr-poc-dataprep-jnl\nmlflowNcdEnv\naml-scikit-learn\nE2E-training-deployment-sample-env-jnl\nr-custom-docker\nr-check\nr-basic-image\nr-basic\nr-base-env\nOR_TechOps_Wally\nRstudio-server-open\ncall-core-env\nCliV2AnonymousEnvironment\ndm-tweet-env\ncargo_env\nOR_TechOps_DWL\nAA-pricing-custompy\ndm-classifer-env\nata-recoder-env\nCR_categorizer_env\nCR_categorizer\ncr_categorizer\nCR_training\ndml\nAce\ndrenv\njordan_test_env\nsmart-standby-pl-env\nrelm-env\nfs-mlflow-env\nengine_llp\nenfine_llp\ntolou_test_env\njordan-test-env\nor_xpress\nstudio\nExperiment prvtssl2 Environment\nExperiment testnewaks1group020 Environment\nExperiment testenewaks Environment\nlarch\neQSIenv2\neQSIenv\nmygpuenv\nmyenv\nExperiment PS_failure_prediction Environment\ncustomize_AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference-sklearn\ncustomize_AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference\nsmart-standby-fs-env\ndr-env\nrake-env\ntitanic-test-env\ntitanic-env\nExperiment ShutdownCI_cloned_pipeline Environment\nbawg-env\nExperiment MetaGene2Vec Environment\nlocal-env\norion-default\ndocker-env\nraven_traffic_env_botorch\norion-default-env\nmy-test-env-default\nmy-test-env\nchk-schd-wed-env\nExperiment optuna_experiment_v1 Environment\nraven_traffic_env_1\nraven_traffic_env\nExperiment p-group020-exp1 Environment\noptuna_env\noptuna-env\nrapids_env\nsklearn-env\nExperiment example-study Environment\ntest\nuser-managed-env\nsystem-managed-env\noptuna-example1\noptuna-example\noptuna-keras\nExperiment e-sud-t1 Environment\nAutoML-AzureML-AutoML-GPU\nor_env\nr-tolou-mls-headcount-env\nExperiment tolou_oracle_pipeline_v1 Environment\nExperiment anshu_oracle_pipeline_v1 Environment\nExperiment AnshuTestOracleR Environment\nExperiment tolou_oracle_pipeline Environment\nExperiment testakstrain Environment\nExperiment test_r_pipeline Environment\nExperiment dataset_profile Environment\nExperiment AOS_DAILY_PREDICTION Environment\nExperiment MktWeight Environment\nExperiment test_pipeline Environment\nfastai-env\nExperiment BOSS_TEST Environment\ntweets-env\ntutorial-env\ntweet-env\nExperiment ShutdownComputeInstanceDntTouch Environment\nExperiment MICheck Environment\nExperiment ScheduledCIshutDown Environment\nExperiment DemoSchedulePythonScriptGithub Environment\nExperiment ScheduleTest Environment\nAutoML-AzureML-AutoML\nAzureML-AI-Studio-Development\nAzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\nAzureML-ACPT-pytorch-1.12-py38-cuda11.6-gpu\nAzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu\nAzureML-ACPT-pytorch-1.11-py38-cuda11.5-gpu\nAzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\nAzureML-responsibleai-0.21-ubuntu20.04-py38-cpu\nAzureML-responsibleai-0.20-ubuntu20.04-py38-cpu\nAzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\nAzureML-tensorflow-2.6-ubuntu20.04-py38-cuda11-gpu\nAzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu\nAzureML-sklearn-1.0-ubuntu20.04-py38-cpu\nAzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu\nAzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu\nAzureML-pytorch-1.8-ubuntu18.04-py37-cuda11-gpu\nAzureML-sklearn-0.24-ubuntu18.04-py37-cpu\nAzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\nAzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu\nAzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu\nAzureML-Triton\nAzureML-Designer-Score\nAzureML-VowpalWabbit-8.8.0\nAzureML-PyTorch-1.3-CPU\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708723111620
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = ml_client.environments.get(name=\"jordan-spark-env\", version=\"1\")\n",
        "print(env)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "conda_file:\n  channels:\n  - conda-forge\n  dependencies:\n  - python==3.9\n  - openjdk\n  - pip\n  - pip:\n    - pandas\n    - pyspark\n    - delta-spark\n    - findspark\n  name: preprocessing_env\ncreation_context:\n  created_at: '2024-01-29T19:33:50.043281+00:00'\n  created_by: Drizen\n  created_by_type: User\n  last_modified_at: '2024-01-29T19:33:50.043281+00:00'\n  last_modified_by: Drizen\n  last_modified_by_type: User\nid: azureml:/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourceGroups/ba-p-zeaus-group020-rg/providers/Microsoft.MachineLearningServices/workspaces/p-group020-aml-ws-001/environments/jordan-spark-env/versions/1\nimage: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\nname: jordan-spark-env\nos_type: linux\ntags: {}\nversion: '1'\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708723154733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\n",
        "print(env. description, env.tags)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "An environment for tasks such as regression, clustering, and classification with Scikit-learn. Contains the Azure ML SDK and additional python packages. {'Scikit-learn': '0.24.1', 'OS': 'Ubuntu18.04', 'Training': ''}\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708723492821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "mslearn"
    },
    "kernelspec": {
      "name": "mslearn",
      "language": "python",
      "display_name": "mslearn"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}