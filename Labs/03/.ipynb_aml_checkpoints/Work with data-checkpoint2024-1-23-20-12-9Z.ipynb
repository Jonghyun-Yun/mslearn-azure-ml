{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Work with Data\n",
        "\n",
        "Data is the foundation on which machine learning models are built. Managing data centrally in the cloud, and making it accessible to teams of data scientists who are running experiments and training models on multiple workstations and compute targets is an important part of any professional data science solution.\n",
        "\n",
        "In this notebook, you'll explore two Azure Machine Learning objects for working with data: *datastores*, and *data assets*.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.13.0\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/mslearn/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1708703880392
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ml_client = MLClient(DefaultAzureCredential(), ws.subscription_id, ws.resource_group, ws.name)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708709641756
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "# ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/ba-p-zeaus-746220-e2v5o1/code/.azureml/config.json\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1708703885381
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## List the datastores\n",
        "\n",
        "When you create the Azure Machine Learning workspace, an Azure Storage Account is created too. The Storage Account includes Blob and file storage and are automatically connected with your workspace as **datastores**. You can list all datastores connected to your workspace:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores = ml_client.datastores.list()\n",
        "for ds_name in stores:\n",
        "    print(ds_name.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sbpnr\naacompii\nnexidiaraw\naacomtest\nshinyin\nstageraveninputshare\nstageravenoutputshare\nravenoutputshare\nraveninputshare\nboost_prod\nboost_stage\nc360offerfiles\nc360adm\nworkspaceartifactstore\nsurveytest\nc360admdata\nc360ih\nc360_ih\naacom_pii\npgroup020amlstorage001_azureml\ntmattpkg_prod_pkg\ngroup020piiorionadls\ngroup020orionadls\nworkspacecodestore\nazureml_globaldatasets\nworkspaceblobstore\nworkspacefilestore\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1708710815351
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Note the `workspaceblobstore` which connects to the **azureml-blobstore-...** container you explored earlier. The `workspacefilestore` connects to the **code-...** file share."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a datastore\n",
        "\n",
        "Whenever you want to connect another Azure storage service with the Azure Machine Learning workspace, you can create a datastore. Note that creating a datastore, creates the connection between your workspace and the storage, it doesn't create the storage service itself. \n",
        "\n",
        "To create a datastore and connect to a (already existing) storage, you'll need to specify:\n",
        "\n",
        "- The class to indicate with what type of storage service you want to connect. The example below connects to a Blob storage (`AzureBlobDatastore`).\n",
        "- `name`: The display name of the datastore in the Azure Machine Learning workspace.\n",
        "- `description`: Optional description to provide more information about the datastore.\n",
        "- `account_name`: The name of the Azure Storage Account.\n",
        "- `container_name`: The name of the container to store blobs in the Azure Storage Account.\n",
        "- `credentials`: Provide the method of authentication and the credentials to authenticate. The example below uses an account key.\n",
        "\n",
        "**Important**: \n",
        "- Replace the **YOUR-STORAGE-ACCOUNT-NAME** with the name of the Storage Account that was automatically created for you. \n",
        "- Replace the **XXXX-XXXX** for `account_key` with the account key of your Azure Storage Account. \n",
        "\n",
        "Remember you can retrieve the account key by navigating to the [Azure portal](https://portal.azure.com), go to your Storage Account, from the **Access keys** tab, copy the **Key** value for key1 or key2. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AzureBlobDatastore\n",
        "from azure.ai.ml.entities import AccountKeyConfiguration\n",
        "\n",
        "store = AzureBlobDatastore(\n",
        "    name=\"blob_training_data\",\n",
        "    description=\"Blob Storage for training data\",\n",
        "    account_name=\"YOUR-STORAGE-ACCOUNT-NAME\",\n",
        "    container_name=\"training-data\", \n",
        "    credentials=AccountKeyConfiguration(\n",
        "        account_key=\"XXXX-XXXX\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "ml_client.create_or_update(store)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "List the datastores again to verify that a new datastore named `blob_training_data` has been created:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores = ml_client.datastores.list()\n",
        "for ds_name in stores:\n",
        "    print(ds_name.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sbpnr\naacompii\nnexidiaraw\naacomtest\nshinyin\nstageraveninputshare\nstageravenoutputshare\nravenoutputshare\nraveninputshare\nboost_prod\nboost_stage\nc360offerfiles\nc360adm\nworkspaceartifactstore\nsurveytest\nc360admdata\nc360ih\nc360_ih\naacom_pii\npgroup020amlstorage001_azureml\ntmattpkg_prod_pkg\ngroup020piiorionadls\ngroup020orionadls\nworkspacecodestore\nazureml_globaldatasets\nworkspaceblobstore\nworkspacefilestore\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1708718323963
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create data assets\n",
        "\n",
        "To point to a specific folder or file in a datastore, you can create data assets. There are three types of data assets:\n",
        "\n",
        "- `URI_FILE` points to a specific file.\n",
        "- `URI_FOLDER` points to a specific folder.\n",
        "- `MLTABLE` points to a MLTable file which specifies how to read one or more files within a folder.\n",
        "\n",
        "You'll create all three types of data assets to experience the differences between them."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To create a `URI_FILE` data asset, you have to specify a path that points to a specific file. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path. To ensure the data is always available when working with the Azure Machine Learning workspace, local files will automatically be uploaded to the default datastore. In this case, the `diabetes.csv` file will be uploaded to **LocalUpload** folder in the **workspaceblobstore** datastore. \n",
        "\n",
        "To create a data asset from a local file, run the following cell:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading diabetes.csv\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading diabetes.csv\u001b[32m (< 1 MB): 100%|██████████| 518k/518k [00:00<00:00, 15.2MB/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'diabetes-local', 'description': 'Data asset pointing to a local file, automatically uploaded to the default datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourceGroups/ba-p-zeaus-group020-rg/providers/Microsoft.MachineLearningServices/workspaces/p-group020-aml-ws-001/data/diabetes-local/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ba-p-zeaus-746220-e2v5o1/code/Users/746220/azure-ml-labs/Labs/03', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd12cfc4970>, 'serialize': <msrest.serialization.Serializer object at 0x7fd12cfc4cd0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourcegroups/ba-p-zeaus-group020-rg/workspaces/p-group020-aml-ws-001/datastores/workspaceblobstore/paths/LocalUpload/d52d15a0d7d1e95b90a03f146099424a/diabetes.csv', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1708714686484
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'diabetes-datastore-path', 'description': 'Data asset pointing to data-asset-path folder in datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourceGroups/ba-p-zeaus-group020-rg/providers/Microsoft.MachineLearningServices/workspaces/p-group020-aml-ws-001/data/diabetes-datastore-path/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ba-p-zeaus-746220-e2v5o1/code/Users/746220/azure-ml-labs/Labs/03', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd14cdf64d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fd14cdf6920>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourcegroups/ba-p-zeaus-group020-rg/workspaces/p-group020-aml-ws-001/datastores/blob_training_data/paths/data-asset-path/', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1708715322185
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading data (0.52 MBs): 100%|██████████| 518211/518211 [00:00<00:00, 4187540.40it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./diabetes.csv'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'diabetes-table', 'description': 'MLTable pointing to diabetes.csv in data folder', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourceGroups/ba-p-zeaus-group020-rg/providers/Microsoft.MachineLearningServices/workspaces/p-group020-aml-ws-001/data/diabetes-table/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ba-p-zeaus-746220-e2v5o1/code/Users/746220/azure-ml-labs/Labs/03', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd12d01b130>, 'serialize': <msrest.serialization.Serializer object at 0x7fd12d01ba00>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourcegroups/ba-p-zeaus-group020-rg/workspaces/p-group020-aml-ws-001/datastores/workspaceblobstore/paths/LocalUpload/45c4bb11b5759d37974b72b7b978482e/data/', 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1708715379482
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Morteza_test1\nScheduledShutdownCiList\nmnist_opendataset\nMorteza_test2\nncbcruns\nMD-Regression_-_Automobile_Price_Prediction_(Basic)-Train_Model-Trained_model-fb404f70\nTD-Regression_-_Automobile_Price_Prediction_(Basic)-Clean_Missing_Data-Cleaning_transformation-f6dc0eb1\nbankmarketing\nNYCTaxi\nTraining\nTrain\nROracle\nAzureML_workshop\nTaxi_Green_Dataset\ndemo-automl\nnyc-tax-demo\ndemo-nyc-cab-fares\nSE_Station_DFW\nSD_Station_DFW\nNP_Traffic_Reporting\nraven-runs-355350\nraven-runs-1356372\nraven-runs\ntest\nPilotTraining\nPilotHiringModified\nMD-Recommendation_-_Movie_Rating_Tweets-Train_SVD_Recommender-Trained_SVD_recommendation-df60d319\nMD-Binary_Classification_-_Customer_Relationship_Prediction-Train_Model-Trained_model-ef1acaf1\nTD-Binary_Classification_-_Customer_Relationship_Prediction-Clean_Missing_Data-Cleaning_transformation-95f6b40f\nMD-Binary_Classification_-_Customer_Relationship_Prediction-Train_Model-Trained_model-973aa815\nCR_complaints\nRaven_run_1000\nRaven-run-455394\nRaven-run-342355\nRaven-run-343351\nRaven-marketshare\nRaven-ms-2022cal\nRaven-ms-coefficients\ntest-from-datastore-ui.txt\nAA_com_local_storage\ndr-baseline\ndr-target\ndr-baseline-demo\ndr-target-demo\njdbc-driver-test\natarec_9999\natarec_train\natarec_test\natarec_9999_train_balanced_160\natarec_9999_test_balanced\nconnectme_training_data\nbaggage_data_csv_2023-08-03_182124_UTC\nbag_cr\natarec_train_data_filtered_shuffled_final\natarec_test_data_filtered_shuffled_final\nX_filtered\nX_test_selected\nltr\nX_train_selected_text\nX_val_selected_text\nX_test_selected_text\nX_train_selected_embed\nX_train_selected_embedd\nX_val_selected_embedd\nX_val_selected_embeddd\natarec_train_data_augmented\natarec_test_data_filtered_shuffled_final_cleaned\natarec_train_data_augmented_balanced\natarec_test_data_filtered_shuffled_final_cleanedd\natarec_train_data_augmented_balanced_final\natarec_test_data_filtered_shuffled_final_cleaned_final\natarec_train_data_filtered_shuffled_finall\natarec_train_last\natarec_val_last\natarec_train_last_new\natarec_val_last_new\ndiabetes-dev-folder\nlocal-folder-example-diabetes\ndiabetes-local\ndiabetes-datastore-path\ndiabetes-table\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1708715383522
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n0    1354778            0            171                      80   \n1    1147438            8             92                      93   \n2    1640031            7            115                      47   \n3    1883350            9            103                      78   \n4    1424119            1             85                      59   \n\n   TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0                34            23  43.509726          1.213191   21     False  \n1                47            36  21.240576          0.158365   23     False  \n2                52            35  41.511523          0.079019   23     False  \n3                25           304  29.582192          1.282870   43      True  \n4                27            35  42.604536          0.549542   22     False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1708716213510
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1708716293688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing src/move-data.py\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/group020orionadls/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"ba-p-zeaus-746220-e2v5o1\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.0 MBs): 100%|██████████| 1113/1113 [00:00<00:00, 72703.01it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/olden_nest_ppx6ccgmh6?wsid=/subscriptions/c450f3d1-583c-495f-b5d3-0b38b99e70c0/resourcegroups/ba-p-zeaus-group020-rg/workspaces/p-group020-aml-ws-001&tid=49793faf-eb3f-4d99-a0cf-aef7cce79dc1\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1708717626546
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "mslearn"
    },
    "kernelspec": {
      "name": "mslearn",
      "language": "python",
      "display_name": "mslearn"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}